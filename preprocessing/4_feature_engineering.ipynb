{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_feature_engineering.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "wcIv5V4GgZyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "outputId": "acc4b434-e332-4d96-aa21-3fa4fbd203d3"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install gensim\n",
        "!pip3 install fuzzywuzzy\n",
        "!pip3 install textblob"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/a4/d10c0acc8528d838cda5eede0ee9c784caa598dbf40bd0911ff8d067a7eb/gensim-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (23.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 23.6MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/1f/6f27e3682124de63ac97a0a5876da6186de6c19410feab66c1543afab055/smart_open-1.7.1.tar.gz\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 14.9MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/b9/7df67f1775d240ac8d111211f967fa75ecc9968ae79ffa0594e36345445f/boto3-1.9.62-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 26.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n",
            "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 19.8MB/s \n",
            "\u001b[?25hCollecting botocore<1.13.0,>=1.12.62 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/77/35e82076e3beb506280f94213a258819378115f174e516ce69b3a2336e1c/botocore-1.12.62-py2.py3-none-any.whl (5.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.1MB 6.1MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting docutils>=0.10 (from botocore<1.13.0,>=1.12.62->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 23.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Building wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/23/00/44/e5b939f7a80c04e32297dbd6d96fa3065af89ecf57e2b5f89f\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.49.0 boto3-1.9.62 botocore-1.12.62 bz2file-0.98 docutils-0.14 gensim-3.6.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.7.1\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.17.0\n",
            "Collecting textblob\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/7d/ad09a26b63d4ad3f9395840c72c95f2fc9fa2b192094ef14e9e720be56f9/textblob-0.15.2-py2.py3-none-any.whl (636kB)\n",
            "\u001b[K    100% |████████████████████████████████| 645kB 20.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.11.0)\n",
            "Installing collected packages: textblob\n",
            "Successfully installed textblob-0.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mQkhb0E4gcZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ab1a1113-05ea-422a-a76c-3b0cbd68e518"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from gensim.similarities import WmdSimilarity\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "\n",
        "from gensim import corpora\n",
        "import gensim.downloader as api\n",
        "from gensim.matutils import softcossim\n",
        "from gensim.models import Word2Vec\n",
        "from fuzzywuzzy import fuzz\n",
        "from nltk.corpus import stopwords\n",
        "from tqdm import tqdm_notebook\n",
        "from nltk import word_tokenize\n",
        "from scipy.stats import skew, kurtosis\n",
        "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix  \n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "from textblob import Word\n",
        "from textblob import TextBlob\n",
        "import spacy\n",
        "\n",
        "!python -m spacy download en_core_web_lg\n",
        "nlp = spacy.load('en_core_web_lg')  \n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz#egg=en_core_web_lg==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_lg -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en_core_web_lg\n",
            "\n",
            "    You can now load the model via spacy.load('en_core_web_lg')\n",
            "\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "thc3DGkcgt3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "1118132e-9412-42f7-9557-57e928712608"
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dIQWIJq_xmRo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Loading data**"
      ]
    },
    {
      "metadata": {
        "id": "iRHnUdBGhDSY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_path = os.path.join('drive','My Drive','quora','train_data_v3_processed.csv')\n",
        "train_data = pd.read_csv(train_path)\n",
        "train_data = train_data.dropna(how=\"any\").reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nZfBxZcM8DoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "243227ce-c4ab-4865-b0b2-81e343a05d6b"
      },
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>question1_lemma</th>\n",
              "      <th>question1_tag</th>\n",
              "      <th>question2_lemma</th>\n",
              "      <th>question2_tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "      <td>what be the step by step guide to invest in sh...</td>\n",
              "      <td>WP VBZ DT NN IN NN NN TO VB IN NN NN IN NN .</td>\n",
              "      <td>what be the step by step guide to invest in sh...</td>\n",
              "      <td>WP VBZ DT NN IN NN NN TO VB IN NN NN .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>what be the story of kohinoor ( koh - i - noor...</td>\n",
              "      <td>WP VBZ DT NN IN NNP -LRB- NNP HYPH NNP HYPH NN...</td>\n",
              "      <td>what would happen if the indian government ste...</td>\n",
              "      <td>WP MD VB IN DT JJ NN VBD DT NNP -LRB- NNP HYPH...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "      <td>how can -PRON- increase the speed of -PRON- in...</td>\n",
              "      <td>WRB MD PRP VB DT NN IN PRP$ NN NN IN VBG DT NNP .</td>\n",
              "      <td>how can internet speed be increase by hack thr...</td>\n",
              "      <td>WRB MD VB NN VB VBN IN VBG IN NN .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "      <td>why be -PRON- mentally very lonely ? how can -...</td>\n",
              "      <td>WRB VBP PRP RB RB JJ . WRB MD PRP VB PRP .</td>\n",
              "      <td>find the remainder when [ math]23^{24}[/math ]...</td>\n",
              "      <td>VB DT NN WRB -LRB- NN -RRB- VBZ VBN IN CD .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "      <td>which one dissolve in water quikly sugar , sal...</td>\n",
              "      <td>WDT CD NN IN NN RB NN , NN , NN CC NN FW NN .</td>\n",
              "      <td>which fish would survive in salt water ?</td>\n",
              "      <td>WDT NN MD VB IN NN NN .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                          question1  \\\n",
              "0   0  What is the step by step guide to invest in sh...   \n",
              "1   1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2   2  How can I increase the speed of my internet co...   \n",
              "3   3  Why am I mentally very lonely? How can I solve...   \n",
              "4   4  Which one dissolve in water quikly sugar, salt...   \n",
              "\n",
              "                                           question2  is_duplicate  \\\n",
              "0  What is the step by step guide to invest in sh...             0   \n",
              "1  What would happen if the Indian government sto...             0   \n",
              "2  How can Internet speed be increased by hacking...             0   \n",
              "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
              "4            Which fish would survive in salt water?             0   \n",
              "\n",
              "                                     question1_lemma  \\\n",
              "0  what be the step by step guide to invest in sh...   \n",
              "1  what be the story of kohinoor ( koh - i - noor...   \n",
              "2  how can -PRON- increase the speed of -PRON- in...   \n",
              "3  why be -PRON- mentally very lonely ? how can -...   \n",
              "4  which one dissolve in water quikly sugar , sal...   \n",
              "\n",
              "                                       question1_tag  \\\n",
              "0       WP VBZ DT NN IN NN NN TO VB IN NN NN IN NN .   \n",
              "1  WP VBZ DT NN IN NNP -LRB- NNP HYPH NNP HYPH NN...   \n",
              "2  WRB MD PRP VB DT NN IN PRP$ NN NN IN VBG DT NNP .   \n",
              "3         WRB VBP PRP RB RB JJ . WRB MD PRP VB PRP .   \n",
              "4      WDT CD NN IN NN RB NN , NN , NN CC NN FW NN .   \n",
              "\n",
              "                                     question2_lemma  \\\n",
              "0  what be the step by step guide to invest in sh...   \n",
              "1  what would happen if the indian government ste...   \n",
              "2  how can internet speed be increase by hack thr...   \n",
              "3  find the remainder when [ math]23^{24}[/math ]...   \n",
              "4           which fish would survive in salt water ?   \n",
              "\n",
              "                                       question2_tag  \n",
              "0             WP VBZ DT NN IN NN NN TO VB IN NN NN .  \n",
              "1  WP MD VB IN DT JJ NN VBD DT NNP -LRB- NNP HYPH...  \n",
              "2                 WRB MD VB NN VB VBN IN VBG IN NN .  \n",
              "3        VB DT NN WRB -LRB- NN -RRB- VBZ VBN IN CD .  \n",
              "4                            WDT NN MD VB IN NN NN .  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "Iq7gIwl9xsYL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ]
    },
    {
      "metadata": {
        "id": "ympwxsUbs4Wr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "QUESTION1 = 'question1_lemma'\n",
        "QUESTION2 = 'question2_lemma'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PqVDm-r3hN8L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## TODO DELETE\n",
        "#train_data['question1_lemma'] = train_data['question1']\n",
        "#train_data['question2_lemma'] = train_data['question2']\n",
        "#train_data = train_data[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ea1An26khvdF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Fuzzy features**"
      ]
    },
    {
      "metadata": {
        "id": "1IoCVY3vh2Nr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def setFuzzyFeatures(df):  \n",
        "  df['fuzz_ratio'] = df.apply(lambda x: fuzz.ratio(str(x[QUESTION1]), str(x[QUESTION2])), axis=1)\n",
        "  df['fuzz_partial_ratio'] = df.apply(lambda x: fuzz.partial_ratio(str(x[QUESTION1]), str(x[QUESTION2])), axis=1)\n",
        "  df['fuzz_partial_token_set_ratio'] = df.apply(lambda x: fuzz.partial_token_set_ratio(str(x[QUESTION1]), str(x[QUESTION2])), axis=1)\n",
        "  df['fuzz_partial_token_sort_ratio'] = df.apply(lambda x: fuzz.partial_token_sort_ratio(str(x[QUESTION1]), str(x[QUESTION2])), axis=1)\n",
        "  df['fuzz_token_set_ratio'] = df.apply(lambda x: fuzz.token_set_ratio(str(x[QUESTION1]), str(x[QUESTION2])), axis=1)\n",
        "  df['fuzz_token_sort_ratio'] = df.apply(lambda x: fuzz.token_sort_ratio(str(x[QUESTION1]), str(x[QUESTION2])), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FFWtoHdFjXYH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **String features**"
      ]
    },
    {
      "metadata": {
        "id": "8eJPiDtejVWI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _avg_word(sentence):\n",
        "  words = sentence.split()\n",
        "  return (sum(len(word) for word in words)/len(words))\n",
        "\n",
        "def _numStopWords(sentence):\n",
        "  return len([x for x in sentence.split() if x in stop_words])\n",
        "\n",
        "def _numNumbers(sentence):\n",
        "  return len([x for x in sentence.split() if x.isdigit()])\n",
        "\n",
        "def _numUppercaseWords(sentence):\n",
        "  return len([x for x in sentence.split() if x.isupper()])\n",
        "\n",
        "def setStringFeatures(df):  \n",
        "  df['len_q1'] = df.question1.apply(lambda x: len(str(x)))\n",
        "  df['len_q2'] = df.question2.apply(lambda x: len(str(x)))\n",
        "  df['diff_len'] = df.len_q1 - df.len_q2\n",
        "  df['len_char_q1'] = df.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
        "  df['len_char_q2'] = df.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
        "  df['len_word_q1'] = df.question1.apply(lambda x: len(str(x).split()))\n",
        "  df['len_word_q2'] = df.question2.apply(lambda x: len(str(x).split()))\n",
        "  df['common_words'] = df.apply(lambda x: len(set(str(x[QUESTION1]).lower().split()).intersection(set(str(x[QUESTION2]).lower().split()))), axis=1)\n",
        "  df['avg_word_q1'] = df.question1.apply(lambda x: _avg_word(x))\n",
        "  df['avg_word_q2'] = df.question2.apply(lambda x: _avg_word(x))\n",
        "  df['num_stop_words_q1'] = df.question1.apply(lambda x: _numStopWords(x))\n",
        "  df['num_stop_words_q2'] = df.question2.apply(lambda x: _numStopWords(x))\n",
        "  df['numerics_q1'] = df.question1.apply(lambda x: _numNumbers(x))\n",
        "  df['numerics_q2'] = df.question2.apply(lambda x: _numNumbers(x))\n",
        "  df['uppercase_q1'] = df.question1.apply(lambda x: _numUppercaseWords(x))\n",
        "  df['uppercase_q2'] = df.question2.apply(lambda x: _numUppercaseWords(x))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IrqdfZPMpk0l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Word2Vec features**"
      ]
    },
    {
      "metadata": {
        "id": "2cz9B7_7purJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w2v_model = api.load(\"word2vec-google-news-300\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2JqcTURRpsw8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _getDictionary(df):  \n",
        "  documents = list(df[QUESTION1].apply(lambda x: x.split()))+list(df[QUESTION2].apply(lambda x: x.split()))\n",
        "  \n",
        "  return corpora.Dictionary(documents)\n",
        "   \n",
        "def _softCossim(row, dictionary, similarity_matrix):\n",
        "  q1 = row[QUESTION1].split()\n",
        "  q2 = row[QUESTION2].split()\n",
        "  \n",
        "  q1 = dictionary.doc2bow(q1)\n",
        "  q2 = dictionary.doc2bow(q2)\n",
        "  \n",
        "  return softcossim(q1, q2, similarity_matrix)\n",
        " \n",
        "def setWord2VecFeatures(df):\n",
        "  dictionary = _getDictionary(df)\n",
        "  similarity_matrix = w2v_model.similarity_matrix(dictionary)\n",
        "  \n",
        "  df['softcossim'] = df.apply(lambda row: _softCossim(row, dictionary, similarity_matrix), axis=1)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lhC06hXRw0BQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **TextBlob**"
      ]
    },
    {
      "metadata": {
        "id": "S_rWf2qKw1vD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _numSpellingMistakes(sentence):\n",
        "  mistakes = 0\n",
        "  for word in sentence.split():\n",
        "    if TextBlob(word).correct() != word:\n",
        "      mistakes += 1\n",
        "  return mistakes\n",
        "\n",
        "\n",
        "def setTextBlobFeatures(df):\n",
        "  df['mistakes_q1'] = df.question1.apply(lambda x: _numSpellingMistakes(x))\n",
        "  df['mistakes_q2'] = df.question2.apply(lambda x: _numSpellingMistakes(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DbUwzjaQ3HmE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Spacy**"
      ]
    },
    {
      "metadata": {
        "id": "6QbLzl3T3JHX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _getSpacySimilarity(row):\n",
        "  q1 = row[QUESTION1]\n",
        "  q2 = row[QUESTION2]\n",
        "  \n",
        "  tokens1 = nlp(Q1)\n",
        "  tokens2 = nlp(Q2)\n",
        "  \n",
        "  return tokens1.similarity(tokens2)\n",
        "\n",
        "def setSpacyFeatures(df):\n",
        "  df['spacy_sim'] = df.apply(lambda row: _getSpacySimilarity(row), axis=1)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q6njwe-nw8Ys",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Merge Features **Functions**"
      ]
    },
    {
      "metadata": {
        "id": "KZo6EjeZw_U1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def setFeatures(df):\n",
        "  setFuzzyFeatures(df)\n",
        "  setStringFeatures(df)\n",
        "  setWord2VecFeatures(df)\n",
        "  setTextBlobFeatures(df)\n",
        "  setSpacyFeatures(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GKbdzMkfm4IC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Execution**"
      ]
    },
    {
      "metadata": {
        "id": "sgV9BW05m7_H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = train_data#.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "itHCMS4YnAHG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "setFeatures(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LkAytFEInF7N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}