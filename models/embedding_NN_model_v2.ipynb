{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zenbook/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense,LSTM,subtract,Input,SimpleRNN, Embedding, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../common/')\n",
    "import csv_utils\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('..','data','train_data_v2.csv')\n",
    "train_data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = train_data.loc[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          question1  \\\n",
       "0   0  What is the step by step guide to invest in sh...   \n",
       "1   1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2  How can I increase the speed of my internet co...   \n",
       "3   3  Why am I mentally very lonely? How can I solve...   \n",
       "4   4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100 # Quora only allows 150 characters\n",
    "'''\n",
    "input:\n",
    "    - train: raw text of training\n",
    "    - test: raw text of testing\n",
    "ouput:\n",
    "    - train: processed training\n",
    "    - test: processed testing\n",
    "    - vocab: Number of vocaboluary\n",
    "'''\n",
    "def prep_data(train, test):\n",
    "    tokenizer = Tokenizer()\n",
    "    # Training the tokenizer with the words from all questions from training\n",
    "    tokenizer.fit_on_texts(train[0] + train[1])\n",
    "\n",
    "    # Convert each word to a integer according to the tokenizer\n",
    "    q1_train = tokenizer.texts_to_sequences(train[0])\n",
    "    q2_train = tokenizer.texts_to_sequences(train[1])\n",
    "    q1_test = tokenizer.texts_to_sequences(test[0])\n",
    "    q2_test = tokenizer.texts_to_sequences(test[1])\n",
    "\n",
    "    # Add a left pad to make all the question have the same length\n",
    "    q1_train = pad_sequences(q1_train, maxlen=MAX_LENGTH)\n",
    "    q2_train = pad_sequences(q2_train, maxlen=MAX_LENGTH)\n",
    "    q1_test = pad_sequences(q1_test, maxlen=MAX_LENGTH)\n",
    "    q2_test = pad_sequences(q2_test, maxlen=MAX_LENGTH)\n",
    "\n",
    "    train = q1_train, q2_train, train[2]\n",
    "    # In case that the testing comes with labels, we need to return the labels as well\n",
    "    if len(test) == 3:\n",
    "        test = q1_test, q2_test, test[2]\n",
    "    else:\n",
    "        test = q1_test, q2_test\n",
    "    \n",
    "    return train, test, len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data[['question1', 'question2', 'is_duplicate']].values\n",
    "train, test = train_test_split(data, test_size=0.33, random_state=42)\n",
    "train = train.T\n",
    "test = test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, vocab = prep_data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "DROPOUT_RATE = 0.5\n",
    "LAMBDA_REGULARIZER = 0.03\n",
    "\n",
    "def get_model(vocab):\n",
    "    # Network design\n",
    "    #\n",
    "    # Q1 -> Embedding -> Conv1 -> MaxPooling -> Flatten \\\n",
    "    #                                                    -> Concatenate -> FC layers -> output\n",
    "    # Q2 -> Embedding -> Conv1 -> MaxPooling -> Flatten /\n",
    "    #\n",
    "    input_q1 = Input(shape=(MAX_LENGTH,), dtype='int32')\n",
    "    input_q2 = Input(shape=(MAX_LENGTH,), dtype='int32')\n",
    "\n",
    "    embd_q1 = Embedding(vocab, EMBEDDING_DIM, input_length=MAX_LENGTH)(input_q1)\n",
    "    embd_q2 = Embedding(vocab, EMBEDDING_DIM, input_length=MAX_LENGTH)(input_q2)\n",
    "    \n",
    "    drop_q1 = Dropout(DROPOUT_RATE)(embd_q1)\n",
    "    drop_q2 = Dropout(DROPOUT_RATE)(embd_q2)\n",
    "    \n",
    "    conv_q1 = Conv1D(256, 3, activation='relu', padding='same')(drop_q1)\n",
    "    conv_q2 = Conv1D(256, 3, activation='relu', padding='same')(drop_q2)\n",
    "    \n",
    "    for i in range(3):\n",
    "        conv_q1 = Conv1D(256, 3, activation='relu', padding='same')(conv_q1)\n",
    "        conv_q2 = Conv1D(256, 3, activation='relu', padding='same')(conv_q2)\n",
    "        conv_q1 = MaxPooling1D(2)(conv_q1)\n",
    "        conv_q2 = MaxPooling1D(2)(conv_q2)\n",
    "\n",
    "    flatten_q1 = Flatten()(conv_q1)\n",
    "    flatten_q2 = Flatten()(conv_q2)\n",
    "    \n",
    "    concat = concatenate([flatten_q1,flatten_q2])\n",
    "    concat = Dropout(DROPOUT_RATE)(concat)\n",
    "    \n",
    "    for i in range(3):\n",
    "        concat = Dense(units=16, activation='relu')(concat)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(LAMBDA_REGULARIZER))(concat)\n",
    "\n",
    "    model = Model(inputs=[input_q1, input_q2], outputs=output)\n",
    "    model.compile(optimizer='adadelta',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['binary_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(vocab)\n",
    "model.fit([train[0], train[1]],\n",
    "          train[2],\n",
    "          validation_data = ([test[0], test[1]],test[2]),\n",
    "          batch_size=256,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('embedding_NN_model.h5')\n",
    "#model = load_model('embedding_NN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=[test[0], test[1]], y=test[2], batch_size=256) # "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Outcomes from Colab Google:\n",
    "\n",
    "106643/106643 [==============================] - 28s 267us/step\n",
    "[0.5297254649741214, 0.7712461202301321]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict([test[0], test[1]], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predicted.ravel()\n",
    "predicted = list(map(lambda x: 1 if x > 0.5 else 0, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with the real test now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('..','data','test_data.csv')\n",
    "test_data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[['question1', 'question2', 'is_duplicate']].values\n",
    "test = test_data[['question1', 'question2']].values\n",
    "train = train.T\n",
    "test = test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, vocab = prep_data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 100, 100)     8682800     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 100, 100)     8682800     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100, 100)     0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 100, 100)     0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 100, 256)     77056       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 100, 256)     77056       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 100, 256)     196864      conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 100, 256)     196864      conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 50, 256)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 50, 256)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 50, 256)      196864      max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 50, 256)      196864      max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 25, 256)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 25, 256)      0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 25, 256)      196864      max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 25, 256)      196864      max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 12, 256)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 12, 256)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3072)         0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 3072)         0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6144)         0           flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 6144)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           98320       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           272         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           272         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            17          dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 18,799,777\n",
      "Trainable params: 18,799,777\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('embedding_NN_model_v2.h5') # Model trained in Colab Google\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict([test[0], test[1]], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predicted.ravel()\n",
    "predicted = list(map(lambda x: 1 if x > 0.5 else 0, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved in:  /home/zenbook/Work/github/quora_npl/models/../data/submissions/submission_0230PM-November-25-2018.csv\n"
     ]
    }
   ],
   "source": [
    "csv_utils.create_csvs(predicted, test_data.test_id.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score in Kaggle: 0.78318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
